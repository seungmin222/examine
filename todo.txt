//기능구현
2. 서버 배포 및 로그인 등 구현(나중에) ////////////
5. 크롤링으로 최신 논문, examine 토픽 등 가져오기 ////////////
8. 유명인들 보충제 목록 정리 및 크롤링으로 업데이트(심랜드, 브존, 커즈와일 등) ////
9. 로그인 시 본인 영양제 스택 정리 기능 및 구매 간접 장바구니 기능
11.기대효과, 부작용 상세페이지 추가
12.추천 제품 리스트 및 가격, 컨슈머랩 fda 결과 등 나열
13.회사별 종합 신뢰도 평가(fda 검사, 기타 중금속, 함량 등)
15.즐겨찾기, 메모, 공유 //////////// 로컬스토리지
17.업데이트 내역 //////////////
18.로그인 시 문서작성 가능 및 작성내역 저장
20.쿠키 저장-> 테마 등
21.성분별 인기도 분석(연령대, 나라, 성별 분류)
29.정렬 필드 제한 (enum + 검증) 실무에선 이런 필드값을 하드코딩하지 않고, 미리 백엔드에서 허용된 필드만 프론트에 전달해서 선택하게 하는 것도 좋아.
30.데이터 로딩 개수 제한 두기 ex)30개 로딩하고 추가 로딩 버튼
31.테이블 태그 클릭하면 필터링
32.검색창에 입력하면 일치후보들 10개 정도 띄우기
34.논문에 티어 추가되면 연관 성분-해당 효과 별로 티어 평균 계산
36.태그 리퀘스트에 있는 type이 의미가 있나?
38.보안(함수 복호화, ip 차단 등)
41.semanticscholar은 api 제한이 있으므로 대책 강구->임시로 api 막힐시 웹 크롤링 추가시도
42.조회수에 따른 대규모 동시성 고려, 아키텍처 및 cs 응용, 조회수를 정렬에도 추가
43.사이트 전체 조회수도 고려
44.이용자별 권한 차등 부여
45.그 외 백엔드 성능 고려(ex)정렬, 필터링의 알고리즘과 아키텍처)
55.크롤링으로 자동 가격 비교 및 시간대별 가격 추이 분석
56.핫딜
58.기존 초기화 버튼을 row 정보 불러오는 걸로 바꾸고 항목 전체 해제 버튼 새로 만들기
65.참가자 만명 이상일시 --만명으로 생략표시
68.상세페이지에 모달 두개 삽입
69.논문 신뢰점수도 따로 구현
72.js함수 리팩터링
73.td 그냥 하드코딩
74.오른쪽 nav-var는 설정버튼 열면 열리도록
75.ai 적극 활용(논문 링크 입력하면 자동 해석 하도록/크롤링 대안/fast api)
76.태그 추가는 논문으로 옮기기(ai 자동추가도 고려)
77.aws 1년 프리티어로 서버 배포
78.로그인 토큰 radis로 관리,
79.크롤링 혹은 llm 분석시 사용자 확인 거치기(선택)
80.프엔에서 null값 허용하고 백엔에서 후처리/////////////////
82.dto도 마저 바꾸기
83.korname, engname 하나 비어있을 시 llm으로 자동 추가
84.로그인 시 로그인버튼 로그아웃으로 변경,
//
// 이해

1.삼항연산자 안에서  a = void x b ? void y c : d가 면 void가 아무 영향없이 실행되고 a에 값도 정상적으로 반한되나?
2.최적화, 보안 기법
3.리눅스 , 계정 생성, 권한 관리, 프로젝트, 서버 관리
4.rest api, json api,

// 암기
프엔 -> 백엔으로 dto 보낼때 필요한 id 등만 보내도 생략된 것들 null값으로 들어감
템플릿 리터럴 사용여부 규칙성 확인

//js

1. 변수 복사시 기본으로 참조복사하기에 const a = [...b]; 이런식의 전개연산자필요
2. 엔티티 수정할 시 db 테이블의 값은 어떤 알고리즘으로 수정하는가?
3. 로컬스토리지는 js 테마색 같은 정보) 빠르고 지속 무한./ 쿠키는 민감 정보) 느리고 세션 만료 있지만 보안 있음
//java



//이전
필요 프로그램:intelji, jdk, mysql workbrench

//코테

시간초과 나면 이분탐색, dp
시간복잡도 같아도 vector가 더 빠를 수 있음 (vector > map > unordered_map)
재귀, dp는 기본적으로 설계한 점화식을 어떻게든 구현했다고 치고 박치기


// 경과
gpt로 프엔 백엔 db 전부 생성
프엔에서 검색, 정렬, 필터링등 처리하다가 백엔으로 이관(api 세분화)
테이블 이름 리펙터링 하면서 매핑 해제, 부여
프엔에서 엔티티 처리하던것도 마저 dto로 변환하면서 중복 코드 제거
논문에서 크롤링을 통해 데이터 추출하는 중 api 제한 걸려서 난항 +
api에 없는 데이터는 직접 본문에서 정규표현식으로 추출하는 중 정확성과 효율 고민
1. 직접 알고리즘 세워서 예외처리
2. NLP기반 기계학습 모델 사용
3. 최후에 직접 입력
4. ai chat 활용(api 비용 발생)

db에 점수 넣을떄 어떤식으로 할지
1. java에서 계산후 대입 : 유지보수 최적
2. db에서 처리 : 성능 최적
이런식으로 시스템 성능을 위한 아키텍처 고민을 다방면으로 고민

속도, 유지보수, 정확성을 등을 타협하는 고민 필요

일단 java에서 실시간으로 계산하되 추후 db 처리로 변경예정

매핑테이블을 백엔드에서 객체로 만들때 객체에 각 매핑된 테이블의 객체들 자체를 저장할지
id만 저장하고 조회할지 고민-> 전자는 공간 up, 후자는 시간 up

백엔드는 무겁고 프엔은 가볍게 처리

기존은 티어, 성분 작용등을 수동입력했으나 점차 자동하중

체크박스 태그버튼 열어야 모달에 정보 로딩되는데 안 누르고 저장버튼 누르면 빈 모달로 정보
덮어씌워지는 문제 모달에 캐시 만들어서 해결함

매핑 중복검사를 위해 Set로 만들었다가 그냥 싹다 삭제하고 새로 만드는 식으로 변경, List로 전환
그런데 매핑을 전부 clear하고 add 하니 세션에 기존 id가 남아있어 중복 id 추가하는 걸로 간주됨
기존 매핑들을 전부 지워야하는데 journal 에 매핑 id 쌍을 직접 저장할지(메모리 증가),
journal id만으로 일일이 다 찾을지 고민: journal 엔티티에 저장된 매핑 id로 set 조회해서 삭제
--> 시간복잡도O(N)에서 O(logN)으로 변경

DELETE CASCADE와 서비스에서 직접 처리하는 것중 고민

@OneToMany(mappedBy = "journal", cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.LAZY)
이렇게 3매핑 테이블을 단순히 lazy 로딩으로 하면 시간이 journal*3매핑 만큼 걸림

@Query("SELECT DISTINCT j FROM Journal j LEFT JOIN FETCH j.journalSupplementEffects")
join fetch로 한꺼번에 join, distinct로 중복 제거

1단계 대안: journal_summary 같은 별도 테이블이나 컬럼에 "비타민C - 항산화, 마그네슘 - 수면" 식으로 텍스트 캐싱.

2단계 대안: 백엔드에서 한번만 조회한 뒤 프론트 캐시 또는 Redis 같은 인메모리 캐시 사용.

3단계 대안: DTO를 만들 때 효과 리스트를 변환해서 문자열로 넣어줌 → HTML에선 이 값만 보여줌.

기존 툴팁을 tooltip::after 로 css에서 생성했지만 나중에 js로 바꿈

테이블의 요소에 클릭 이벤트리스너를 load할떄마다 초기화하는건 비효율적, 추가될때만 초기화하도록 변경

1. 링크를 입력하면 api 기반 크롤링으로 제목, 게재날짜를 크롤링-> 논문엔 정해진 양식이 없으니 한계가 있음
2. ai로 논문 분석(초록만)을 통해 참가자, 기간, 설계디자인, 효과 크기를 가져옴
3. 논문의 신뢰점수를 계산->논문점수와 효과점수를 곱해 논문-성분-효과의 점수를 구함
4. 성분-효과 테이블에 해당 점수들을 취합, 참가자 수에 의한 산술평균으로 성분-효과 점수 구함
5. 절대 기준에 따라 티어 나누기

effect, sideEffect를 인터페이스로 묶어서 오버라이딩, 구조 같응은 함수들 하나로 합침
->레포지토리 호출 함수등 일반화할때 매개변수 많아지는 건 제외

// 살거
 커피,

// 규칙
// 프론트
html,css,js 역할 분담 명확히(하드 코딩 최소화(이미지 등 예외처리등에만 스타일 국소 적용)
모듈화(중복되는 js 함수, html 코드 따로 분리 후 import, css 주기적으로 정리, html 재사용)
재귀함수 아닌 이상 함수모듈화 아무리 해도 자원소모 거의 없음
html에서 기본 로딩(네비게이션바, 스크롤 버튼 등)은 <div id="load-basic>
목차는 index-n 내용은 content-n으로 id 설정(스크롤 및 폴드용)

백엔드
컨트롤러, dto, entity, repository, service로 역할 분담(간단한 것도 일괄 분리)
모듈화(service에 크롤링 등 함수 저장)
repository로 db 조회하는건 리소스가 크므로 반복문으로 조회하지 않고 전부 하나의 리스트로
합치고 한번에 조회

설계디자인 태그는 A+보다 A의 우선순위가 높은 관계 일단 id 순으로 정렬했으나 후처리
내 프로젝트에서 가장 중요한건 테이블 간의 연결성:
   논문에 성분, 효과가 티어와 함께 매핑(티어는 논문 연구 설계 가중치, 표본 개수, 기간 등으로 점수계산 및 알파벳 등급 변환)
-> 해당 성분에 논문 효과들 전부 삽입
-> 성분-효과 매핑 테이블엔 기존 티어(int 점수)들의 총합과 티어의 개수가 저장
-> 공식에 따라 성분별 종합 티어 자동 계산(메타분석 긍정, 코호트 부정일 경우 메타분석 우선하는식으로 가중치 부여)
테이블끼리 긴밀하게 영향을 주는 것이 다른 crud 게시판과의 가장 큰 차이점

점수 계산 공식을 코드로 고정할지, DB에 식별자로 저장해서 유동적으로 바꿀 수 있게 할지

종합 티어를 계산할 때 쿼리 수준에서 처리할지, 아니면 정기적 배치 연산으로 반영할지

논문-성분-효과 3자 관계를 단일 매핑 테이블로 만들지, journal_effect, supplement_effect, journal_supplement_effect 같이 분리할지

중복제거는 HashSet으로
//
슬슬 대화가 길어져서 로딩이 오래 걸리는데 다음 gpt를 위한 프롬포트를 써서 이 대화 내용을 이어나갈 수 있게 해줘. 정리된 전체적인 프로젝트 개요와 구조를 다음 GPT에게도 이해될 수 있도록 설명해 내가 복사해서 붙여넣도록

