gpt로 프엔 백엔 db 전부 생성
프엔에서 검색, 정렬, 필터링등 처리하다가 백엔으로 이관(api 세분화)
테이블 이름 리펙터링 하면서 매핑 해제, 부여
프엔에서 엔티티 처리하던것도 마저 dto로 변환하면서 중복 코드 제거
논문에서 크롤링을 통해 데이터 추출하는 중 api 제한 걸려서 난항 +
api에 없는 데이터는 직접 본문에서 정규표현식으로 추출하는 중 정확성과 효율 고민
1. 직접 알고리즘 세워서 예외처리
2. NLP기반 기계학습 모델 사용
3. 최후에 직접 입력
4. ai chat 활용(api 비용 발생)

db에 점수 넣을떄 어떤식으로 할지
1. java에서 계산후 대입 : 유지보수 최적
2. db에서 처리 : 성능 최적
이런식으로 시스템 성능을 위한 아키텍처 고민을 다방면으로 고민

속도, 유지보수, 정확성을 등을 타협하는 고민 필요

일단 java에서 실시간으로 계산하되 추후 db 처리로 변경예정

매핑테이블을 백엔드에서 객체로 만들때 객체에 각 매핑된 테이블의 객체들 자체를 저장할지
id만 저장하고 조회할지 고민-> 전자는 공간 up, 후자는 시간 up

백엔드는 무겁고 프엔은 가볍게 처리

기존은 티어, 성분 작용등을 수동입력했으나 점차 자동하중

체크박스 태그버튼 열어야 모달에 정보 로딩되는데 안 누르고 저장버튼 누르면 빈 모달로 정보
덮어씌워지는 문제 모달에 캐시 만들어서 해결함

매핑 중복검사를 위해 Set로 만들었다가 그냥 싹다 삭제하고 새로 만드는 식으로 변경, List로 전환
그런데 매핑을 전부 clear하고 add 하니 세션에 기존 id가 남아있어 중복 id 추가하는 걸로 간주됨
기존 매핑들을 전부 지워야하는데 journal 에 매핑 id 쌍을 직접 저장할지(메모리 증가),
journal id만으로 일일이 다 찾을지 고민: journal 엔티티에 저장된 매핑 id로 set 조회해서 삭제
--> 시간복잡도O(N)에서 O(logN)으로 변경

DELETE CASCADE와 서비스에서 직접 처리하는 것중 고민

@OneToMany(mappedBy = "journal", cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.LAZY)
이렇게 3매핑 테이블을 단순히 lazy 로딩으로 하면 시간이 journal*3매핑 만큼 걸림

@Query("SELECT DISTINCT j FROM Journal j LEFT JOIN FETCH j.journalSupplementEffects")
join fetch로 한꺼번에 join, distinct로 중복 제거

1단계 대안: journal_summary 같은 별도 테이블이나 컬럼에 "비타민C - 항산화, 마그네슘 - 수면" 식으로 텍스트 캐싱.

2단계 대안: 백엔드에서 한번만 조회한 뒤 프론트 캐시 또는 Redis 같은 인메모리 캐시 사용.

3단계 대안: DTO를 만들 때 효과 리스트를 변환해서 문자열로 넣어줌 → HTML에선 이 값만 보여줌.

기존 툴팁을 tooltip::after 로 css에서 생성했지만 나중에 js로 바꿈

테이블의 요소에 클릭 이벤트리스너를 load할떄마다 초기화하는건 비효율적, 추가될때만 초기화하도록 변경

1. 링크를 입력하면 api 기반 크롤링으로 제목, 게재날짜를 크롤링-> 논문엔 정해진 양식이 없으니 한계가 있음
2. ai로 논문 분석(초록만)을 통해 참가자, 기간, 설계디자인, 효과 크기를 가져옴
3. 논문의 신뢰점수를 계산->논문점수와 효과점수를 곱해 논문-성분-효과의 점수를 구함
4. 성분-효과 테이블에 해당 점수들을 취합, 참가자 수에 의한 산술평균으로 성분-효과 점수 구함
5. 절대 기준에 따라 티어 나누기

effect, sideEffect를 인터페이스로 묶어서 오버라이딩, 구조 같응은 함수들 하나로 합침
->레포지토리 호출 함수등 일반화할때 매개변수 많아지는 건 제외

dto 두개로 나눔

detail 같은 테이블은 굳이 supplement 엔티티에 필드로 안넣고 필요할때마다 조회

로그인 토큰 redis로 관리, 이후 자동 로그 아웃, 자동 연장 등 구현

디스크, 락, 트랜잭션 상황에 맞게 쓰기

지속적으로 유지보수-성능 고민(row 하나에 여러개의 row를 직접 저장해 조회 속도를 늘릴지, 1대1 매핑해서 속도 낮추고 속도 포기할지(추가로 역방향 조회 어려움))
단방향 매핑의 경우엔 매핑 테이블 없이 저장하는거 고려

구현에만 급급하다 점점 sql, lazy로딩과 select 문에 따른 자원 소모, 대규모 동시성 등을 고려하게 됨

ex) supplement의 연관 테이블들을 따로따로 lazy fetch했지만 한꺼번에 join fetch, 또는 EAGER 도 고려하는 등
핵심은 쿼리 개수 최대한 줄이는것 e.getSupplementEffect.getEffect 이런거
단일 조회는 lazy 로딩, 여러개 조회는 join fetch
하지만 join fetch를 한 쿼리문에 여러번 호출하면 충돌나기에 List 대신 Set를 써야하는데 정렬이 비효율적,
->프엔으로 보낼땐 List로 형변환 후 정렬

기존 태그들은 api 여러번 호출->
태그들을 json 안에서 한번 더 묶어서 api 횟수 줄이기

논문에서 태그 분석 자동화-> 일차적으로 llm에 성분-효과 쌍을 받아옴
-> 각 성분, 효과를 유사도 검사
-> 일정 유사도 이상인 태그들을 추려서 90% 미만인 경우 llm에 추가 확인 및 선택
-> 유사도 높은 태그 10개를 우선순위 큐로 잘라서 llm에 넣기

jse 테이블이 기존 3매핑 테이블이었는데 이를 j-se로 리팩토링
이중매핑 테이블인 se테이블과 j 테이블을 다시 매핑함(정규화)

성능 위해서(se 테이블에 이름 중복 저장)
정규화 vs 성능

join fetch는 늘어날때마다 row 수 기하급수적으로 늘어나므로 하나만 사용

dto 만들때 jpql로 직접 dto까지 만들지, 중간에 서비스로 조립할지

객체 전체 불러오기 할떄 처음엔 laz Loading으로 하나하나 불러옴
-> 쿼리문으로 left join 중첩으로 한번에 불러옴
-> 쿼리문 참조 필드만큼 나눠서 row 개수 늘어나는거 방지
-> left join으로 fetch해서 lazyloading 없이 get 가능하게 함

영속성 컨텍스트 , save, add 매핑 고려
중첩 복합키 구조이므로 안정성 챙기려면 save 필요 add는 ㄴㄴ JPA @MapsId 복잡성 회피

기존엔 논문을 단순링크로 저장했지만 추후 주소, api 바뀌는거 고려해서 사이트 자체 id, 사이트 유형으로 구분

딥링크나 api 등으로 장바구니 직접 추가는 안됨

알람을 보낼때 유저가 많으면 시간에 오차 생길 수 있음.

 @Query("SELECT up.user.id FROM UserPage up WHERE up.page.id = :pageId")
    List<Long> findUserIdsByPageId(@Param("pageId") Long pageId);

@Query("SELECT up.id.userId FROM UserPage up WHERE up.id.pageId = :pageId")
    List<Long> findUserIdsByPageId(@Param("pageId") Long pageId);

    조인 깊이 낮춤

    기본적으로 jpql 사용하되 부분적으로 native query 사용

    jpql내의 native query, queryDSL, mybatis 등 주

    필터링 매서드에서 리미트를 어디다 걸지 고민(전체개수 기준은 성능, 필터링 기준은 사용자)

    첫단추를 꿰는게 중요하다 나중에 리팩토링 할때 몇배는 고생한다


    suggest 결과 map 형태로 캐싱해ㅓ api 호츌 최소화